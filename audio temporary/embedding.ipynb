{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9e095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Run this to activate venv for the terminal instance: .venv\\Scripts\\activate\n",
    "# NOTE: you will also need the ff files:\n",
    "#   -> 'class_labels_indices.csv'\n",
    "#   -> 'Cnn14_mAP=0.431.pth' (these are the model weights to be used) from https://zenodo.org/records/3987831\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "from panns_inference import AudioTagging\n",
    "\n",
    "# Make sure cuda (gpu) is active!\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fa0899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: C:\\Users\\mkyod/panns_data/Cnn14_mAP=0.431.pth\n",
      "GPU number: 1\n",
      "6 WAV files found!\n",
      "\n",
      "Processing: trend3vid6_32k.wav\n",
      "Embedding saved:  embeddings_out\\trend3vid6_32k_embedding2048.npy\n",
      "[0.         0.         0.         ... 0.19923183 0.46746948 0.        ]\n",
      "(2048,)\n",
      "\n",
      "Processing: trend3vid7_32k.wav\n",
      "Embedding saved:  embeddings_out\\trend3vid7_32k_embedding2048.npy\n",
      "[0.        0.        0.        ... 0.        0.8063234 0.       ]\n",
      "(2048,)\n",
      "\n",
      "Processing: trend3vid8_32k.wav\n",
      "Embedding saved:  embeddings_out\\trend3vid8_32k_embedding2048.npy\n",
      "[0.         0.         0.         ... 0.5110518  0.74246013 0.        ]\n",
      "(2048,)\n",
      "\n",
      "Processing: trend5vid2_32k.wav\n",
      "Embedding saved:  embeddings_out\\trend5vid2_32k_embedding2048.npy\n",
      "[0.         0.         0.         ... 0.19942343 0.04068661 0.        ]\n",
      "(2048,)\n",
      "\n",
      "Processing: trend5vid3_32k.wav\n",
      "Embedding saved:  embeddings_out\\trend5vid3_32k_embedding2048.npy\n",
      "[0.         0.         0.         ... 0.22457194 0.02149612 0.        ]\n",
      "(2048,)\n",
      "\n",
      "Processing: trend5vid4_32k.wav\n",
      "Embedding saved:  embeddings_out\\trend5vid4_32k_embedding2048.npy\n",
      "[0.         0.         0.         ... 0.21873716 0.01695281 0.        ]\n",
      "(2048,)\n"
     ]
    }
   ],
   "source": [
    "proc_out_32kHz_dir = Path(\"proc_out_32kHz\")\n",
    "emb_out_dir = Path(\"embeddings_out\") # 2048-d vectors go here\n",
    "emb_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "at_model = AudioTagging(checkpoint_path=None, device=device) #this is the pretrained CNN14\n",
    "\n",
    "wav_files = sorted(proc_out_32kHz_dir.glob(\"*_32k.wav\"))\n",
    "print(f\"{len(wav_files)} WAV files found!\")\n",
    "\n",
    "for wav_path in wav_files:\n",
    "    print(f\"\\nProcessing: {wav_path.name}\")\n",
    "    wav, sr = librosa.load(str(wav_path), sr=32000, mono=True) # just to make sure wav is 32kHz\n",
    "    audio_batch = np.expand_dims(wav, axis=0) # matches the expected shape of PANN\n",
    "\n",
    "    _, embedding = at_model.inference(audio_batch) # gets the embedding as numpy array\n",
    "\n",
    "    embedding_vec = embedding[0] # first element of embedding array\n",
    "\n",
    "    out_path = emb_out_dir / (wav_path.stem + \"_embedding2048.npy\")\n",
    "    np.save(str(out_path), embedding_vec)\n",
    "    print(\"Embedding saved: \", out_path)\n",
    "\n",
    "    print(embedding_vec) # if you want to see the vector\n",
    "    print(embedding_vec.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
