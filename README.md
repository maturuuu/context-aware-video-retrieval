# context-aware-video-retrieval

![License](https://img.shields.io/badge/license-Apache%202.0-blue)

This repository contains the research, data, and code for the undergraduate thesis:

***"Comparing Modality Representation Schemes in Video Retrieval for More Context-Aware Auto-Annotation of Trending Short-Form Videos"***
by Matthew Kristoffer Ong, Shanette Giane Presas, Sophia Althea Sarreal, and Jersey Jaclyn To of the Andrew L. Tan Data Science Institute, De La Salle University Manila.

---

## ğŸ“– Overview

The project focuses on developing a system that explores how different combinations of multimodal features affect the **retrieval of semantically similar videos**, with the goal of finding
the configuration that allows Google Gemini to produce the **most context-aware auto-annotated metadata**.

Key components include:  
- Preprocessing and feature extraction (video, audio, text)  
- Similarity computation and ranking  
- Auto-annotation with Google Gemini

---

## âš™ï¸ Repository Structure

(update this)

---

## ğŸš€ Getting Started

(update this)

---

## ğŸ“« Contact Details

1. Matthew Kristoffer Ong, DLSU-ALTDSI: matthew_kristoffer_ong@dlsu.edu.ph
2. Shanette Giane presas, DLSU-ALTDSI: shanette_giane_presas@dlsu.edu.ph
3. Sophia Althea Sarreal, DLSU-ALTDSI: sophia_sarreal@dlsu.edu.ph
4. Jersey Jaclyn To, DLSU-ALTDSI: jers_to@dlsu.edu.ph

