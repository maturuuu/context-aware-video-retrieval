# -*- coding: utf-8 -*-
"""text embedding - embed concatenate better results

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nNwQhfumzm1Sqvrd7mAemUfA86BI8Ld9

## TEXT EMBEDDING
"""

import os
import json
import numpy as np
import pandas as pd
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# CONFIG
CSV_PATH = "video_text_outputs.csv"
JSON_DIR = "sample_data"
MODEL_NAME = "sentence-transformers/all-mpnet-base-v2"
SAVE_DIR_0 = "base_dir"
SAVE_DIR = os.path.join(SAVE_DIR_0, "text768")
DEVICE = "cuda" if __import__("torch").cuda.is_available() else "cpu"
os.makedirs(SAVE_DIR, exist_ok=True)

# LOAD CSV
df = pd.read_csv(CSV_PATH).fillna("")
df["video_base"] = df["video"].apply(lambda x: os.path.splitext(os.path.basename(str(x)))[0])

# LOAD JSON METADATA
json_map = {}
for fname in os.listdir(JSON_DIR):
    if fname.lower().endswith(".json"):
        json_map[os.path.splitext(fname)[0]] = os.path.join(JSON_DIR, fname)

descs, hashtags_texts = [], []
for base in df["video_base"]:
    path = json_map.get(base)
    if not path:
        descs.append("")
        hashtags_texts.append("")
        continue
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        vm = data.get("video_metadata", data)
        descs.append(vm.get("description", "") or "")
        hashtags = vm.get("hashtags", [])
        if isinstance(hashtags, list):
            hashtags_texts.append(" ".join(f"#{h}" for h in hashtags))
        else:
            hashtags_texts.append(str(hashtags))
    except Exception:
        descs.append("")
        hashtags_texts.append("")

df["description"] = descs
df["hashtags_text"] = hashtags_texts

# LOAD MODEL
model = SentenceTransformer(MODEL_NAME, device=DEVICE)
weights = np.array([0.4, 0.1, 0.3, 0.2])
weights = weights / weights.sum()

# ENCODE EACH MODALITY
modalities = ["ocr_final", "hashtags_text", "asr", "description"]
embs = {}

for m in modalities:
    print(f"Encoding {m}...")
    texts = df[m].fillna("").astype(str).tolist()
    embs[m] = model.encode(texts, batch_size=8, convert_to_numpy=True,
                           show_progress_bar=True, normalize_embeddings=True)

# CONCATENATE TEXTS
df["concatenated_text"] = df.apply(
    lambda row: " ".join([
        str(row.get("ocr_final", "")),
        str(row.get("hashtags_text", "")),
        str(row.get("asr", "")),
        str(row.get("description", ""))
    ]).strip(),
    axis=1
)

print("\n===== CONCATENATED TEXTS =====")
for i, text in enumerate(df["concatenated_text"].tolist(), start=1):
    print(f"[{i}] {text}\n")

# FUSE
combined_embs = (
    weights[0] * embs["ocr_final"] +
    weights[1] * embs["hashtags_text"] +
    weights[2] * embs["asr"] +
    weights[3] * embs["description"]
)

# COSINE SIMILARITY
sim_matrix = cosine_similarity(combined_embs)

def rank_similar_videos(query_index, top_k=10):
    sims = sim_matrix[query_index]
    sorted_idx = np.argsort(-sims)
    query_name = df.iloc[query_index]["video_base"]
    print(f"\nTop similar videos to: {query_name}")
    for i, idx in enumerate(sorted_idx[:top_k]):
        vid = df.iloc[idx]["video_base"]
        print(f"{i+1}. {vid} (similarity: {sims[idx]:.4f})")

# EXAMPLE
rank_similar_videos(0)

import shutil

shutil.rmtree("embeddings_output", ignore_errors=True)
print("âœ… Deleted folder: embeddings_output")

from google.colab import drive
drive.mount('/content/drive')