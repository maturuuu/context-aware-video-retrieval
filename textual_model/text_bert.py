# -*- coding: utf-8 -*-
"""text embedding

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1koMsBrGtLV72blqluLNUGWLOpooh_Adx

## TEXT EMBEDDING
"""

# pip install sentence-transformers torch pandas numpy tqdm

import os
import json
import ast
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
from sentence_transformers import SentenceTransformer

CSV_PATH = "video_text_outputs.csv"
JSON_DIR = "sample_data"
MODEL_NAME = "sentence-transformers/all-MiniLM-L12-v2"
SAVE_DIR = "embeddings_output"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
os.makedirs(SAVE_DIR, exist_ok=True)

def file_base_no_ext(fname):
    return os.path.splitext(os.path.basename(str(fname)))[0]

def build_hashtags_text(hashtags):
    if not hashtags:
        return ""
    if isinstance(hashtags, str):
        try:
            parsed = ast.literal_eval(hashtags)
            if isinstance(parsed, (list, tuple)):
                hashtags = parsed
        except Exception:
            hashtags = [hashtags]
    return " ".join([f"#{h}" if not str(h).startswith("#") else str(h) for h in hashtags if str(h).strip()])

def safe_parse_list_field(x):
    if pd.isna(x) or x is None:
        return []
    if isinstance(x, (list, tuple)):
        return [str(i) for i in x]
    s = str(x).strip()
    if not s:
        return []
    if (s.startswith("[") and s.endswith("]")) or (s.startswith("(") and s.endswith(")")):
        try:
            parsed = ast.literal_eval(s)
            if isinstance(parsed, (list, tuple)):
                return [str(i) for i in parsed]
        except Exception:
            pass
    return [s]

df = pd.read_csv(CSV_PATH, dtype=str).fillna("")
if "video" not in df.columns:
    raise RuntimeError("CSV must include a 'video' column.")

if "asr" not in df.columns:
    alt = [c for c in df.columns if "asr" in c.lower() or "transcript" in c.lower()]
    if alt:
        df.rename(columns={alt[0]: "asr"}, inplace=True)
    else:
        df["asr"] = ""
if "ocr_final" not in df.columns:
    alt = [c for c in df.columns if "ocr" in c.lower()]
    if alt:
        df.rename(columns={alt[0]: "ocr_final"}, inplace=True)
    else:
        df["ocr_final"] = ""

df["video_base"] = df["video"].apply(file_base_no_ext)

json_map = {}
if os.path.isdir(JSON_DIR):
    for fname in os.listdir(JSON_DIR):
        if fname.lower().endswith(".json"):
            json_map[os.path.splitext(fname)[0]] = os.path.join(JSON_DIR, fname)

descs, hashtags_texts = [], []
for base in df["video_base"].tolist():
    p = json_map.get(base)
    if not p:
        descs.append("")
        hashtags_texts.append("")
        continue
    try:
        with open(p, "r", encoding="utf-8") as fh:
            j = json.load(fh)
        vm = j.get("video_metadata", j)
        descs.append(vm.get("description", "") or "")
        hashtags_texts.append(build_hashtags_text(vm.get("hashtags", []) or []))
    except Exception:
        descs.append("")
        hashtags_texts.append("")
df["description"] = descs
df["hashtags_text"] = hashtags_texts

# build full text
def build_full_text(row):
    parts = []
    if row.get("hashtags_text"):
        parts.append(row["hashtags_text"])
    if row.get("description"):
        parts.append(row["description"])
    asr = row.get("asr", "")
    if asr:
        asr_list = safe_parse_list_field(asr)
        parts.append(". ".join([p for p in asr_list if p.strip()]))
    ocr = row.get("ocr_final", "")
    if ocr:
        ocr_list = safe_parse_list_field(ocr)
        parts.append(". ".join([p for p in ocr_list if p.strip()]))
    return ". ".join([p.strip() for p in parts if p.strip()])

df["full_text"] = df.apply(build_full_text, axis=1)

model = SentenceTransformer(MODEL_NAME, device=DEVICE)

all_embs = []
for _, row in tqdm(df.iterrows(), total=len(df), desc="Embedding videos"):
    video_base = row["video_base"]
    text = row["full_text"]
    if not isinstance(text, str) or not text.strip():
        emb = np.zeros(model.get_sentence_embedding_dimension(), dtype=np.float32)
    else:
        emb = model.encode(text, convert_to_numpy=True, normalize_embeddings=True)
    all_embs.append(emb)
    np.save(os.path.join(SAVE_DIR, f"{video_base}_sbert.npy"), emb)

emb_array = np.vstack(all_embs)
np.save(os.path.join(SAVE_DIR, "textual_embeddings.npy"), emb_array)

df.to_csv(os.path.join(SAVE_DIR, "embeddings_metadata.csv"), index=False)

print("âœ… Saved embeddings in:", SAVE_DIR)
